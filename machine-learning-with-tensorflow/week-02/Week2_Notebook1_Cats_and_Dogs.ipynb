{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVw7Aob4X68y"
      },
      "source": [
        "# Image Preprocessing and Binary Classification with Keras\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this week's exercise, you will:\n",
        "1. Learn how to do image preprocessing in Keras\n",
        "2. Build a multilayer neural network for binary classification\n",
        "3. Train the model on a real-world dataset of cats and dogs\n",
        "4. Monitor performance using a validation dataset\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Libraries\n",
        "\n",
        "Let's start by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "amm_E1Z9X68z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, Rescaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdCT_N6IX680"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 2: Load and Preprocess the Data\n",
        "\n",
        "Use `tfds.load()` to load the \"cats_vs_dogs\" dataset.\n",
        "\n",
        "Find a way to split the dataset into a training and a validation set.\n",
        "\n",
        "Also research how to apply necessary preprocessing to the data and do so (some of the preprocessing can also later be done using layers of the model).\n",
        "\n",
        "*Note*: You can also get the dataset from other sources. However, there are some known issues with corrupted images, which then need to be addressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "9b4ca15df1b04e68bbf15b587b5c8e53",
            "0fd5b9bf57eb44d1972706bc54b9ab26",
            "e8d2cd03a649453492f5c62778aba3e8",
            "c8086ab3e3e34c4eb2fb2f394b1e3fc8",
            "70e4ea4635e74b2f94174d2a0afdd874",
            "4a03421d75a048a9a89955a244e8f948",
            "653af760d489419aa6c19664bcb7caac",
            "fb8d424d8d9b48b8b4b34367864de190",
            "1d6e7737cb7047e5a00be1e6f4c56e85",
            "9728177d958746f983bd58e45ad69d03",
            "45ecc19a78094b5cafa22e9ea922797f",
            "b358792bccac4e36854521779530e9f9",
            "bc5a6be091764c7bbc9b6bbfd7017e4f",
            "8abe794a8c544aff8b06d8d7dbac0790",
            "df79241341aa43c684621009151a22e7",
            "cbb3586d130b4d40aa4a3c890fe563cc",
            "45999d3b0b444cfb96545c2f26fc3491",
            "b22c2359930e4ee2898e5bb6526f53a9",
            "8c337b9ab9034235a0abb437803521a5",
            "ef3d17ff8e3e4a1380667de3ebde4d9d",
            "552a7a1078d249f0902632cfe72e2209",
            "d229cb8d33774a1d9b9b3ab2032faa2f",
            "ec717a748d70443ca436f4234971421b",
            "f191b41773664417a1751d52e87a6e65",
            "180cebda3fee4178b83971fe649780da",
            "ed49be6d554d409eb0aee423806d4a9b",
            "649d9893e5b44b5ea953ff088a0fa7be",
            "5d3d0e8085274ae182d32cd476c2c930",
            "4322c6581966469994fcf2cbd0161d93",
            "e1817db3ea6f424189405491fac90409",
            "7fe3b48225814a28804c6bfe72a53f11",
            "43c3be7c3ae343308599c79fe2384df2",
            "204e810888d5402284e6eed332235447",
            "4338265c2c4e4c52830f73214df01a9b",
            "23c3641facba4b709d0aa95225efeba0",
            "e5b242f0d273449981a6ed9e71c1aeda",
            "61818d5901274f4ca886f5e2a716b136",
            "036f6dfed0794500b47ddad299eded78",
            "6ed3fc1ee544461e8889092037e85faa",
            "c7cbc2df21c84474b659d730899d63ee",
            "96f8110d23124dea8f7edf65f6a9b5f7",
            "1e4c5cd014bf4905a2cd3b0b15d83e21",
            "f656f9f6fafd43689cb7b6c11e510119",
            "cf74109fb47e4ef88e8db9836fc22480",
            "4c3818f6ae574ab194ab74d0eef36a09",
            "389e246c3a51438bb2964611b6f19508",
            "120a3a48197a4b1fa12606a59f51f9e8",
            "cdda403ef0574158a7cedc42a81eb00e",
            "a01bdc5286cd4897888f0dab96e956ff",
            "92515fe600844040b51883b627afea76",
            "0b5e58f7718b48daac580cf3278c1176",
            "12b92387aa3e47ac873e0c692ab4a7fa",
            "d869ef90c6564250bc119f322ca20d88",
            "4582b20a12974e759cd5cbb0c3174d76",
            "66fce3551b6c4d9a821cb906ad29c96e"
          ]
        },
        "id": "qKFEOet4X680",
        "outputId": "66b027bb-7235-4870-f7c7-636b7bf3af69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/cats_vs_dogs/4.0.1 has no dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b4ca15df1b04e68bbf15b587b5c8e53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b358792bccac4e36854521779530e9f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec717a748d70443ca436f4234971421b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4338265c2c4e4c52830f73214df01a9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/cats_vs_dogs/incomplete.SIXME6_4.0.1/cats_vs_dogs-train.tfrecord*...:   0%…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3818f6ae574ab194ab74d0eef36a09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\n",
            "Number of training examples: 18624\n",
            "Number of validation examples: 4672\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = 150\n",
        "IMG_HEIGHT = 150\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# Load the dataset and split it\n",
        "dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
        "\n",
        "# For 'cats_vs_dogs', which only has a 'train' split, we'll take a subset for validation manually.\n",
        "# Let's get the number of examples and manually split.\n",
        "num_examples = info.splits['train'].num_examples\n",
        "train_size = int(0.8 * num_examples)\n",
        "val_size = num_examples - train_size\n",
        "\n",
        "full_dataset = dataset['train'].map(preprocess)\n",
        "train_dataset = full_dataset.take(train_size).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "validation_dataset = full_dataset.skip(train_size).take(val_size).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"Number of training examples: {tf.data.experimental.cardinality(train_dataset).numpy() * 32}\")\n",
        "print(f\"Number of validation examples: {tf.data.experimental.cardinality(validation_dataset).numpy() * 32}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDUEOS_oX680"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 3: Build a Multilayer Neural Network\n",
        "\n",
        "Build a multilayer neural network for binary classification. Apply your knowledge from the Coursera lectures to choose an adequate model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "wZgRKdj7X680",
        "outputId": "585617ba-25b3-4e1b-8c16-6dee73aa5947"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,735,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,828,481\u001b[0m (18.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,828,481</span> (18.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,828,481\u001b[0m (18.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,828,481</span> (18.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5), # Add dropout for regularization\n",
        "    Dense(1, activation='sigmoid') # Output layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYdFRTFEX680"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 4: Train the Model\n",
        "\n",
        "Train the model using the training dataset you created. Monitor performance during training using the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u9f0tNmX680",
        "outputId": "4a13de05-a9d9-4811-870d-080540c2fabf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m189/582\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:03\u001b[0m 1s/step - accuracy: 0.5359 - loss: 0.6937"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,  # You can adjust the number of epochs\n",
        "    validation_data=validation_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Dkf_pBX680"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 5: Evaluate the Model\n",
        "\n",
        "After training, you may upload some test images to evaluate your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6KZeMdhX681"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "def load_and_predict(model):\n",
        "    uploaded_files = files.upload()\n",
        "\n",
        "    for fn in uploaded_files.keys():\n",
        "        path = '/content/' + fn\n",
        "        img = image.load_img(path, target_size=(150, 150))\n",
        "\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0) / 255.0\n",
        "\n",
        "        classes = model.predict(x)\n",
        "        result = \"a dog\" if classes[0] > 0.5 else \"a cat\"\n",
        "\n",
        "        print(f'The model predicts that the image is of {result}')\n",
        "\n",
        "# Call the function to upload images and get predictions\n",
        "load_and_predict(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".ve_tensorflow_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
